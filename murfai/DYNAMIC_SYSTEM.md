# Dynamic System Architecture

## Overview

The system has been refactored from hard-coded responses to a fully dynamic, configurable architecture. All responses, templates, and configurations can now be modified without changing code.

## Key Changes

### 1. Dynamic Response Generation

**Before**: Hard-coded if/else statements with fixed responses
```python
if "hello" in message:
    return "Hello! It's so good to hear from you."
```

**After**: LLM-based dynamic response generation
```python
response = await self.response_generator.generate_response(
    user_message=user_message,
    sentiment=sentiment,
    context=context,
    state=self.current_conversation_state
)
```

**Location**: `src/llm/response_generator.py`

**Features**:
- Supports multiple LLM providers (Hugging Face, Groq, rule-based fallback)
- Context-aware responses using conversation history
- Sentiment-based prompt adaptation
- State-aware responses (medication, word of day, etc.)

### 2. Dynamic Configuration System

**Before**: Hard-coded values in `config.py`
```python
VOICE_STYLES = {
    "happy": "Excited",
    "sad": "Whisper"
}
```

**After**: JSON-based configuration file
```json
{
  "voice_styles": {
    "happy": "Excited",
    "sad": "Whisper"
  }
}
```

**Location**: `src/config/dynamic_config.py`, `config.json`

**Features**:
- Load configuration from `config.json`
- Runtime configuration updates
- Dot-notation access: `config.get("llm.provider")`
- Auto-creates default config if missing

### 3. Dynamic Word Database

**Before**: Hard-coded list in Python file
```python
WORD_DATABASE = [
    {"word": "Petrichor", "definition": "..."}
]
```

**After**: Loadable from multiple sources
- **Inline**: From `config.json`
- **File**: From `data/words.json`
- **API**: From external API (future)

**Location**: `src/features/word_of_day.py`

**Usage**:
```python
# Words loaded automatically from config
word_of_day = WordOfTheDay(dynamic_config)
word = word_of_day.get_word_of_day()
```

### 4. Dynamic Medication Reminders

**Before**: Hard-coded message templates
```python
message = f"I noticed it's time for your {med_name}..."
```

**After**: Template-based system
```json
{
  "medication_reminders": {
    "templates": {
      "morning": "I noticed it's {time}. Usually, we take {medication}..."
    }
  }
}
```

**Location**: `src/features/medication_reminder.py`

**Features**:
- Time-of-day specific templates
- Customizable follow-up messages
- Easy to add new templates

### 5. Dynamic Voice Styles

**Before**: Hard-coded in config
```python
VOICE_STYLES = {"happy": "Excited"}
```

**After**: Configurable via JSON
```json
{
  "voice_styles": {
    "happy": "Excited",
    "sad": "Whisper",
    "neutral": "Conversational"
  }
}
```

## Configuration File Structure

### `config.json`

The main configuration file supports:

```json
{
  "llm": {
    "provider": "huggingface",  // or "groq", "local"
    "api_key": "",              // Optional for Hugging Face
    "model": "microsoft/DialoGPT-medium",
    "temperature": 0.7,
    "max_tokens": 100
  },
  "voice_styles": {
    "happy": "Excited",
    "sad": "Whisper",
    "neutral": "Conversational",
    "calm": "Soft"
  },
  "word_database": {
    "source": "inline",         // "inline", "file", or "api"
    "file_path": "data/words.json",
    "words": [...]
  },
  "medication_reminders": {
    "templates": {...},
    "follow_ups": {...}
  },
  "conversation": {
    "max_context_length": 5,
    "response_max_length": 150
  },
  "features": {
    "medication_reminders": true,
    "word_of_day": true,
    "sentiment_analysis": true,
    "sundowning_support": true
  }
}
```

## LLM Providers

### 1. Hugging Face (Default, Free)
- **Model**: `microsoft/DialoGPT-medium`
- **API Key**: Optional (some models don't require it)
- **Speed**: Moderate
- **Cost**: Free tier available

### 2. Groq (Fast, Free Tier)
- **Model**: `llama-3.1-8b-instant`
- **API Key**: Required (free tier available)
- **Speed**: Very fast
- **Cost**: Free tier with generous limits

### 3. Rule-Based Fallback
- **Provider**: Built-in
- **Speed**: Instant
- **Cost**: Free
- **Use**: When LLM APIs are unavailable

## How to Customize

### 1. Change LLM Provider

Edit `config.json`:
```json
{
  "llm": {
    "provider": "groq",
    "api_key": "your_groq_api_key"
  }
}
```

Or set environment variable:
```bash
export LLM_PROVIDER=groq
export GROQ_API_KEY=your_key
```

### 2. Add Custom Words

Edit `config.json`:
```json
{
  "word_database": {
    "words": [
      {
        "word": "YourWord",
        "definition": "definition here",
        "prompt": "Question to ask?",
        "follow_up": "Follow-up response"
      }
    ]
  }
}
```

Or use external file:
```json
{
  "word_database": {
    "source": "file",
    "file_path": "data/custom_words.json"
  }
}
```

### 3. Customize Medication Reminders

Edit `config.json`:
```json
{
  "medication_reminders": {
    "templates": {
      "morning": "Good morning! Time for {medication} at {time}.",
      "custom": "Your custom template with {medication} and {time}"
    },
    "follow_ups": {
      "custom_response": "Your custom follow-up for {medication}"
    }
  }
}
```

### 4. Adjust Voice Styles

Edit `config.json`:
```json
{
  "voice_styles": {
    "happy": "Excited",
    "sad": "Whisper",
    "neutral": "Conversational",
    "calm": "Soft",
    "custom_emotion": "CustomStyle"
  }
}
```

### 5. Modify System Prompts

The system prompt is dynamically built in `response_generator.py`. To customize:

Edit `src/llm/response_generator.py`:
```python
def _build_system_prompt(self, sentiment: str, context: str, state: str) -> str:
    base_prompt = """Your custom system prompt here..."""
    # Add sentiment/state-specific guidance
    return base_prompt
```

## Runtime Updates

Configuration can be updated at runtime:

```python
from src.config.dynamic_config import DynamicConfig

config = DynamicConfig()
config.set("llm.provider", "groq")
config.set("voice_styles.happy", "VeryExcited")
config.save_config()  # Persists to file
```

## Benefits of Dynamic System

1. **No Code Changes**: Modify behavior via configuration
2. **Easy Customization**: JSON-based configuration
3. **Multiple LLM Options**: Switch providers easily
4. **Extensible**: Add new features via config
5. **Runtime Updates**: Change behavior without restart
6. **A/B Testing**: Easy to test different configurations

## Migration from Hard-Coded

The system maintains backward compatibility:
- If `config.json` doesn't exist, defaults are used
- Rule-based fallback if LLM fails
- All hard-coded values have defaults

## Performance

- **LLM Response Time**: 1-3 seconds (depending on provider)
- **Rule-Based Fallback**: < 1ms
- **Config Loading**: < 10ms
- **Word Loading**: < 50ms (from file)

## Future Enhancements

1. **API-Based Word Loading**: Load words from external API
2. **Dynamic Prompt Templates**: Load prompts from config
3. **Multi-Language Support**: Language-specific configs
4. **User Profiles**: Per-user configuration
5. **Configuration UI**: Web interface for config management

## Troubleshooting

### LLM Not Working
- Check API keys in `.env` or `config.json`
- Verify provider is correct
- Check internet connection
- System falls back to rule-based automatically

### Config Not Loading
- Ensure `config.json` exists (auto-created on first run)
- Check JSON syntax is valid
- Review logs for errors

### Words Not Loading
- Verify `word_database.source` in config
- Check file path if using file source
- Ensure words array is not empty

---

**The system is now fully dynamic and configurable!** ðŸŽ‰

